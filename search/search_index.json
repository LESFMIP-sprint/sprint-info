{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About The LESFMIP analysis sprint is intended for the LEADER and EPESC communities to encourage active analysis of the LESFMIP simulations and facilitate discussion and collaboration. When: 17-20 March 2025 Daily discussion sessions at 12 and 22 pm UTC on Zoom What to do before the Sprint: Request a JASMIN account and make sure you can access the LEADER-EPESC group workspace Make sure you have signed up on the spreadsheet! Emails will only be sent to registered participants Soon: Make sure you have been invited and can access the lesfmip-sprint Slack channel (note: invitations yet to be sent out!) Soon: Make sure you have received and can access the Zoom meetings at 12 pm and 22 pm UTC (note: invitations yet to be sent out!) Useful links: JASMIN notebook server and instructions Publications Soon :)","title":"About"},{"location":"#about","text":"The LESFMIP analysis sprint is intended for the LEADER and EPESC communities to encourage active analysis of the LESFMIP simulations and facilitate discussion and collaboration. When: 17-20 March 2025 Daily discussion sessions at 12 and 22 pm UTC on Zoom What to do before the Sprint: Request a JASMIN account and make sure you can access the LEADER-EPESC group workspace Make sure you have signed up on the spreadsheet! Emails will only be sent to registered participants Soon: Make sure you have been invited and can access the lesfmip-sprint Slack channel (note: invitations yet to be sent out!) Soon: Make sure you have received and can access the Zoom meetings at 12 pm and 22 pm UTC (note: invitations yet to be sent out!) Useful links: JASMIN notebook server and instructions","title":"About"},{"location":"#publications","text":"Soon :)","title":"Publications"},{"location":"FAQ/","text":"FAQ Slack How can I access the CANARI Slack workspace? The CANARI Slack workspace can be accessed online here . If you do not yet have an account you can request one by emailing Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) directly and they can add you to the CANARI Slack workspace. How do I join channels on Slack? You can see all the channels which already exist in the CANARI Slack workspace by scrolling to the bottom of the list of channels, just before direct messages and there should be an option '+ Add channels'. Clicking on '+ Add channels' will bring up 2 options, choose 'Browse Channels' and you will get a list of all the channels and they will all an option to join them when you hover over them. All channels specific to for the sprint will be labeled 'sprint' and channels specific to ask for help are labeled 'sprint-help'. Can I make my own channel on the CANARI Slack workspace for the sprint? Everyone is welcome to make their own slack channels to help collaborate during the sprint. When creating a new channel specifically for the sprint please name it starting with 'sprint-'. Python Do I have to use python? No, you are not required to use python to do analysis during the sprint. Feel free to use whatever you are familiar with. However, you are limited by what is available on JASMIN. The list of what is available on JASMIN can be found here . How can do I access the Jupiter notebook service on JASMIN? See Configuring and Using the JASMIN Notebooks Service on the Tutorial page. General How much am I expected to participate? You can participate as much or little as you like, from listening to the highlights to actively taking part all week. Not sure what to work on Take a look at the participant list and connect with someone who has similar interests to you. Additionally tune in to Monday afternoon's talks on storylines and ensemble member selection. Am I limited to analysing with the future projection, SSP3-7.0, ensemble data? While the intension of the second sprint is to kickstart the analysis of the CANARI-LE future projection data, it is not limited to this. Everyone is more than welcome to investigate the historical CANARI-LE data. What should I do if I want to share about the sprint on social media? Please tag @CANARI_Science in you X/Twitter posts. @CANARI_Science will all be tweeting updates throughout the event, please feel free to retweet those as well.","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#slack","text":"How can I access the CANARI Slack workspace? The CANARI Slack workspace can be accessed online here . If you do not yet have an account you can request one by emailing Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) directly and they can add you to the CANARI Slack workspace. How do I join channels on Slack? You can see all the channels which already exist in the CANARI Slack workspace by scrolling to the bottom of the list of channels, just before direct messages and there should be an option '+ Add channels'. Clicking on '+ Add channels' will bring up 2 options, choose 'Browse Channels' and you will get a list of all the channels and they will all an option to join them when you hover over them. All channels specific to for the sprint will be labeled 'sprint' and channels specific to ask for help are labeled 'sprint-help'. Can I make my own channel on the CANARI Slack workspace for the sprint? Everyone is welcome to make their own slack channels to help collaborate during the sprint. When creating a new channel specifically for the sprint please name it starting with 'sprint-'.","title":"Slack"},{"location":"FAQ/#python","text":"Do I have to use python? No, you are not required to use python to do analysis during the sprint. Feel free to use whatever you are familiar with. However, you are limited by what is available on JASMIN. The list of what is available on JASMIN can be found here . How can do I access the Jupiter notebook service on JASMIN? See Configuring and Using the JASMIN Notebooks Service on the Tutorial page.","title":"Python"},{"location":"FAQ/#general","text":"How much am I expected to participate? You can participate as much or little as you like, from listening to the highlights to actively taking part all week. Not sure what to work on Take a look at the participant list and connect with someone who has similar interests to you. Additionally tune in to Monday afternoon's talks on storylines and ensemble member selection. Am I limited to analysing with the future projection, SSP3-7.0, ensemble data? While the intension of the second sprint is to kickstart the analysis of the CANARI-LE future projection data, it is not limited to this. Everyone is more than welcome to investigate the historical CANARI-LE data. What should I do if I want to share about the sprint on social media? Please tag @CANARI_Science in you X/Twitter posts. @CANARI_Science will all be tweeting updates throughout the event, please feel free to retweet those as well.","title":"General"},{"location":"cf_python/","text":"Computing indices with cf-python cf-python is a python Earth Science data analysis library that is built on a complete implementation of the CF data model. It makes reading, writing and processing of cf netcdf data very simple. This tutorial points to some basic examples for use on the CANARI SPRINT data on JASMIN These examples can all be found in /home/users/dlrhodso/CANARI/SPRINT_2024/examples . All sumbit submit multiple jobs in parallel in order to process all ensemble members at once. They use the LOTUS script to do this - this is a wrapper script for the SLURM submission commands that make it very easy to submit jobs and not worry about log files etc. All these scripts use the default JASMIN sci JASPY enviromnet ( module load jaspy ) - but the LOTUS script automatically loads JASPY. Computing a box average NAO index compute_nao.sh loops over all MSLP files in the /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 directory and uses the compute_nao.py python script to compute the NAO index. #!/usr/bin/env python import cf import sys import glob from origin import * def get_NAO_djf(field): ''' Compute a DJF NAO index by box averaging Azores (20:28W,36:40N) - Iceland (16:25W,63:70N) and averaging over Dec-Jan-Feb ''' #assume field== MSLP! #get sub-regions for boxes iceland_box=field.subspace(X=cf.wi(-25,-16),Y=cf.wi(63,70)) azores_box=field.subspace(X=cf.wi(-28,-20),Y=cf.wi(36,40)) #compute the area means (weighted by cell area) and difference nao=azores_box.collapse('area: mean',weights=True,squeeze=True)-iceland_box.collapse('area: mean', weights=True,squeeze=True) #compute the DJF mean nao_mean=nao.collapse('time: mean',group=cf.djf()) #change the name nao_mean.standard_name='NAO_djf' #And the netcdf name nao_mean.nc_set_variable('NAO_djf') #and the long_name nao_mean.set_properties({'long_name':'NAO_djf'}) #return nao index return(nao_mean) #Atmosphere grid cell area areacella='/home/users/dlrhodso/CANARI/SPRINT_2024/analysis/areacella_fx_HadGEM3-GC31-MM_piControl_r1i1p1f1_gn_fixed.nc' #a tag definining what this index is outfile_origin=\"DJF NAO index computed as the Azores (20:28W, 36:40N) box mean minus Iceland (16:25W,63:70N) box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the MSLP diagnostic (m01s16i222) #Only daily mean MSLP is available file=sys.argv[2]+'/ATM/yearly/*/*day_m01s16i222*' #expand this pattern files=glob.glob(file) #create output filename outfilename=scratch+'/nao-djf_'+files[0].split('/')[-1] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacella) #compute nao index nao_djf=get_NAO_djf(data[0]) #write out NAO index with description text o_write(nao_djf,outfilename,outfile_origin) print(\"Written \"+outfilename) This script will write the output to scratch_pw3/NAO/ as files for each ensemble member Computing a box average index for SST compute_SPG_T.sh #!/usr/bin/env python import cf import sys import glob from origin import * def compute_spg(field): ''' compute SPG 50:65N 0:60W ''' #compute SPG over 50:65N, 0:60W and 1st ocean layer (0:1m) #extract subspace sub_field=field.subspace(latitude=cf.wi(50,65),longitude=cf.wi(-60,0)).squeeze() #compute mean over subspace, weighting by area spg=sub_field.collapse('area: mean', weights='area',squeeze=True) #add names spg.standard_name='sub_polar_gyre_index_50_65N' spg.nc_set_variable('SPG_50_65N') spg.set_properties({'long_name':'sub_polar_gyre_50_60N'}) return(spg) #ocean cell area file areacello=\"areacello.nc\" #a tag definining what this index is outfile_origin=\"SubPolar Gyre Temperaure index computed as the box mean of over () box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the SST diagnostic #file to read in file=sys.argv[2] #file name to write out outfilename=sys.argv[3] #variable name variable=sys.argv[4] #expand this pattern year,fname=file.split('/')[-2:] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacello) if len(data)>1: print(\"Aggregation failed!\") exit() #axis labels need to be added data[0].coord('long_name=cell index along first dimension').axis='X' data[0].coord('long_name=cell index along second dimension').axis='Y' #compute spg index varname=\"SPG_\"+variable index=compute_spg(data[0]) index.standard_name=varname index.nc_set_variable(varname) #compute the monthly means index_monthly=index.collapse('time: mean', group=cf.M()) index_monthly.standard_name=varname+\"_mon\" index_monthly.nc_set_variable(varname+\"_mon\") #compute the annual means index_annual=index.collapse('time: mean', group=cf.Y()) index_annual.standard_name=varname+\"_ann\" index_annual.nc_set_variable(varname+\"_ann\") outlist=cf.FieldList() outlist.append(index) outlist.append(index_monthly) outlist.append(index_annual) #write out NAO index with description text o_write(outlist,outfilename,outfile_origin) print(\"Written \"+outfilename) This produces multiple files in scratch_pw3 that need to be assembled into a single file for each ensemble member. concat_SPG_T.sh does this usings concat_cf.py .","title":"Computing indices with cf-python"},{"location":"cf_python/#computing-indices-with-cf-python","text":"cf-python is a python Earth Science data analysis library that is built on a complete implementation of the CF data model. It makes reading, writing and processing of cf netcdf data very simple. This tutorial points to some basic examples for use on the CANARI SPRINT data on JASMIN These examples can all be found in /home/users/dlrhodso/CANARI/SPRINT_2024/examples . All sumbit submit multiple jobs in parallel in order to process all ensemble members at once. They use the LOTUS script to do this - this is a wrapper script for the SLURM submission commands that make it very easy to submit jobs and not worry about log files etc. All these scripts use the default JASMIN sci JASPY enviromnet ( module load jaspy ) - but the LOTUS script automatically loads JASPY.","title":"Computing indices with cf-python"},{"location":"cf_python/#computing-a-box-average-nao-index","text":"compute_nao.sh loops over all MSLP files in the /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 directory and uses the compute_nao.py python script to compute the NAO index. #!/usr/bin/env python import cf import sys import glob from origin import * def get_NAO_djf(field): ''' Compute a DJF NAO index by box averaging Azores (20:28W,36:40N) - Iceland (16:25W,63:70N) and averaging over Dec-Jan-Feb ''' #assume field== MSLP! #get sub-regions for boxes iceland_box=field.subspace(X=cf.wi(-25,-16),Y=cf.wi(63,70)) azores_box=field.subspace(X=cf.wi(-28,-20),Y=cf.wi(36,40)) #compute the area means (weighted by cell area) and difference nao=azores_box.collapse('area: mean',weights=True,squeeze=True)-iceland_box.collapse('area: mean', weights=True,squeeze=True) #compute the DJF mean nao_mean=nao.collapse('time: mean',group=cf.djf()) #change the name nao_mean.standard_name='NAO_djf' #And the netcdf name nao_mean.nc_set_variable('NAO_djf') #and the long_name nao_mean.set_properties({'long_name':'NAO_djf'}) #return nao index return(nao_mean) #Atmosphere grid cell area areacella='/home/users/dlrhodso/CANARI/SPRINT_2024/analysis/areacella_fx_HadGEM3-GC31-MM_piControl_r1i1p1f1_gn_fixed.nc' #a tag definining what this index is outfile_origin=\"DJF NAO index computed as the Azores (20:28W, 36:40N) box mean minus Iceland (16:25W,63:70N) box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the MSLP diagnostic (m01s16i222) #Only daily mean MSLP is available file=sys.argv[2]+'/ATM/yearly/*/*day_m01s16i222*' #expand this pattern files=glob.glob(file) #create output filename outfilename=scratch+'/nao-djf_'+files[0].split('/')[-1] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacella) #compute nao index nao_djf=get_NAO_djf(data[0]) #write out NAO index with description text o_write(nao_djf,outfilename,outfile_origin) print(\"Written \"+outfilename) This script will write the output to scratch_pw3/NAO/ as files for each ensemble member","title":"Computing a box average NAO index"},{"location":"cf_python/#computing-a-box-average-index-for-sst","text":"compute_SPG_T.sh #!/usr/bin/env python import cf import sys import glob from origin import * def compute_spg(field): ''' compute SPG 50:65N 0:60W ''' #compute SPG over 50:65N, 0:60W and 1st ocean layer (0:1m) #extract subspace sub_field=field.subspace(latitude=cf.wi(50,65),longitude=cf.wi(-60,0)).squeeze() #compute mean over subspace, weighting by area spg=sub_field.collapse('area: mean', weights='area',squeeze=True) #add names spg.standard_name='sub_polar_gyre_index_50_65N' spg.nc_set_variable('SPG_50_65N') spg.set_properties({'long_name':'sub_polar_gyre_50_60N'}) return(spg) #ocean cell area file areacello=\"areacello.nc\" #a tag definining what this index is outfile_origin=\"SubPolar Gyre Temperaure index computed as the box mean of over () box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the SST diagnostic #file to read in file=sys.argv[2] #file name to write out outfilename=sys.argv[3] #variable name variable=sys.argv[4] #expand this pattern year,fname=file.split('/')[-2:] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacello) if len(data)>1: print(\"Aggregation failed!\") exit() #axis labels need to be added data[0].coord('long_name=cell index along first dimension').axis='X' data[0].coord('long_name=cell index along second dimension').axis='Y' #compute spg index varname=\"SPG_\"+variable index=compute_spg(data[0]) index.standard_name=varname index.nc_set_variable(varname) #compute the monthly means index_monthly=index.collapse('time: mean', group=cf.M()) index_monthly.standard_name=varname+\"_mon\" index_monthly.nc_set_variable(varname+\"_mon\") #compute the annual means index_annual=index.collapse('time: mean', group=cf.Y()) index_annual.standard_name=varname+\"_ann\" index_annual.nc_set_variable(varname+\"_ann\") outlist=cf.FieldList() outlist.append(index) outlist.append(index_monthly) outlist.append(index_annual) #write out NAO index with description text o_write(outlist,outfilename,outfile_origin) print(\"Written \"+outfilename) This produces multiple files in scratch_pw3 that need to be assembled into a single file for each ensemble member. concat_SPG_T.sh does this usings concat_cf.py .","title":"Computing a box average index for SST"},{"location":"creating_your_own_conda_env/","text":"Tutorial 3 - Creating and sharing your own conda/mamba environment Why create your own environment? The provided environment (located in /gws/smf/j04/canari/conda-env) contains many packages you are likely to need, but doesn't contain everything. As this is a shared environment we can't allow everyone to install new packages into it. If you need extra packages you will have to create your own environment. Creating an environment from JASMIN If you are running inside terminal on the notebook service you will already have conda (and mamba) in your path. If you are running on a sci server you may need to load the jaspy module by running module load jaspy in order to have the conda/mamba commands in your path. It is assumed you have cloned the tutorials Github repository into a directory called tutorials, if you haven't see the \"Getting the CANARI example code\" section of tutorial 2 (Configuring and Using the JASMIN Notebooks Service). In a terminal run the command mamba env create -n canari -f ~/tutorials/environment.yml . We are using the command mamba instead of conda . Mamba is a replacement for conda that can resolve the dependencies for an enviroment much faster. This will take about 10 minutes to execute. After it is complete, verify it exists by running: mamba env list , you should see something similar to the following: # conda environments: # /gws/smf/j04/canari/conda-env canari /home/users/colinsau/.conda/envs/canari To make the enviroment visible to Jupyter Lab run (\"CANARI-mine\" is the name it will show in the Jupyter Launcher, feel free to change this): mamba run -n canari python -m ipykernel install --user --name CANARI-mine . After about one minute a new icon called \"CANARI-mine\" should apear in the Jupyter launcher on the notebook service. Adding extra packages to your environment Installing extra packages with Mamba We can install extra packages in our mamba/conda enviroment by using the mamba install command from a terminal inside the JASMIN notebook service. We need to specify the name of our enviroment with the -n option. If for example we wanted to install plotnine (which creates R ggplot2 style plots in Python) then we could install it by typing: mamba install -n canari plotnine Installing extra packages with Pip Sometimes packages aren't available via Mamba/Conda but are available via Python's pip package manager. Always try to install via Mamba in the first instance though. To install plotnine using pip run the command: mamba run -n canari pip install plotnine If you already installed plotnine using mamba then this will detect the installation and refuse to install it again. Sharing your enviroment Now you've added more packages to your enviroment you might want to share your enviroment with somebody else (or yourself on a different computer). Mamba/Conda allows us to export a list of all packages installed in an enviroment with the mamba env export command. An example use of this command is: mamba env export -n canari --from-history -f new_environment.yml As with other Mamba commands this takes a -n parameter for the name of the enviroment we're exporting. The option --from-history this means that the export will reflect the package versions we specified, for example we might have requested Python version 3.10.12 instead of the exact version we got which might have been something like version 3.10.2=hd12c33a_0_cpython. These overly precise version numbers can cause problems when trying to replicate the enviroment on another computer, especially if it runs a different operating system. We can specify an output file with the -f parameter, if this isn't specified then the environment data is displayed on screen. The resulting file (new_enviroment.yml) can now be shared with somebody else or added to a git repository. To install a new enviroment using this file run the command mamba env create -n canari-new -f new_enviroment.yml . This will create a new enviorment called \"canari-new\" from the file new_enviroment.yml that we just exported.","title":"Creating your own conda env"},{"location":"creating_your_own_conda_env/#tutorial-3-creating-and-sharing-your-own-condamamba-environment","text":"","title":"Tutorial 3 - Creating and sharing your own conda/mamba environment"},{"location":"creating_your_own_conda_env/#why-create-your-own-environment","text":"The provided environment (located in /gws/smf/j04/canari/conda-env) contains many packages you are likely to need, but doesn't contain everything. As this is a shared environment we can't allow everyone to install new packages into it. If you need extra packages you will have to create your own environment.","title":"Why create your own environment?"},{"location":"creating_your_own_conda_env/#creating-an-environment-from-jasmin","text":"If you are running inside terminal on the notebook service you will already have conda (and mamba) in your path. If you are running on a sci server you may need to load the jaspy module by running module load jaspy in order to have the conda/mamba commands in your path. It is assumed you have cloned the tutorials Github repository into a directory called tutorials, if you haven't see the \"Getting the CANARI example code\" section of tutorial 2 (Configuring and Using the JASMIN Notebooks Service). In a terminal run the command mamba env create -n canari -f ~/tutorials/environment.yml . We are using the command mamba instead of conda . Mamba is a replacement for conda that can resolve the dependencies for an enviroment much faster. This will take about 10 minutes to execute. After it is complete, verify it exists by running: mamba env list , you should see something similar to the following: # conda environments: # /gws/smf/j04/canari/conda-env canari /home/users/colinsau/.conda/envs/canari To make the enviroment visible to Jupyter Lab run (\"CANARI-mine\" is the name it will show in the Jupyter Launcher, feel free to change this): mamba run -n canari python -m ipykernel install --user --name CANARI-mine . After about one minute a new icon called \"CANARI-mine\" should apear in the Jupyter launcher on the notebook service.","title":"Creating an environment from JASMIN"},{"location":"creating_your_own_conda_env/#adding-extra-packages-to-your-environment","text":"","title":"Adding extra packages to your environment"},{"location":"creating_your_own_conda_env/#installing-extra-packages-with-mamba","text":"We can install extra packages in our mamba/conda enviroment by using the mamba install command from a terminal inside the JASMIN notebook service. We need to specify the name of our enviroment with the -n option. If for example we wanted to install plotnine (which creates R ggplot2 style plots in Python) then we could install it by typing: mamba install -n canari plotnine","title":"Installing extra packages with Mamba"},{"location":"creating_your_own_conda_env/#installing-extra-packages-with-pip","text":"Sometimes packages aren't available via Mamba/Conda but are available via Python's pip package manager. Always try to install via Mamba in the first instance though. To install plotnine using pip run the command: mamba run -n canari pip install plotnine If you already installed plotnine using mamba then this will detect the installation and refuse to install it again.","title":"Installing extra packages with Pip"},{"location":"creating_your_own_conda_env/#sharing-your-enviroment","text":"Now you've added more packages to your enviroment you might want to share your enviroment with somebody else (or yourself on a different computer). Mamba/Conda allows us to export a list of all packages installed in an enviroment with the mamba env export command. An example use of this command is: mamba env export -n canari --from-history -f new_environment.yml As with other Mamba commands this takes a -n parameter for the name of the enviroment we're exporting. The option --from-history this means that the export will reflect the package versions we specified, for example we might have requested Python version 3.10.12 instead of the exact version we got which might have been something like version 3.10.2=hd12c33a_0_cpython. These overly precise version numbers can cause problems when trying to replicate the enviroment on another computer, especially if it runs a different operating system. We can specify an output file with the -f parameter, if this isn't specified then the environment data is displayed on screen. The resulting file (new_enviroment.yml) can now be shared with somebody else or added to a git repository. To install a new enviroment using this file run the command mamba env create -n canari-new -f new_enviroment.yml . This will create a new enviorment called \"canari-new\" from the file new_enviroment.yml that we just exported.","title":"Sharing your enviroment"},{"location":"data/","text":"Data The CANARI-LE has now completed running on ARCHER2. The CANARI-LE consists of 40 ensemble members of both the CMIP6 historical simulation and SSP3-7.0. Data is stored on tape in JASMIN and priority data in stored on the JASMIN CANARI group workspace (gws). Ensemble Details Model: HadGEM3-GC1.3-MM, same configuration as used in CMIP6, global configuration version 3.1 Ocean: NEMO3.6 Atmosphere: UM Sea Ice: CICE Land: Jules 40 historical (1950-2014) ensemble members 40 future projection, SSP3-7.0 (2015-2100) ensemble members More information on the CANARI-LE can be found here . Data Access To access the CANARI-LE data available on JASMIN you need to apply for access to the CANARI gws through the JASMIN accounts portal under the my services button. CANARI-LE data can be found here (/gws/nopw/j04/canari/shared/large-ensemble/priority/). HIST2 contains the 40 historical ensemble members, 1950-2014, SSP370 the future projection ensemble members, 2015-2100, and HIST1 are the 4 historical ensemble members which were part of CMIP6, 1850-2014. The list of priority variables are on this spreadsheet . You can find the long names for the variables and the short names used in the netcdf files. Please pay particular attention to the notes in red. Useful Files For the ocean the mesh_mask and subbasins files can be found in the CANARI gws here /gws/nopw/j04/canari/shared/large-ensemble/ocean How to cite There is no specific paper yet on the large ensemble, so please reference the HadGEM3.1 paper ( Williams et al. 2017 ) and acknowledge CANARI and JASMIN. HadGEM3-GC3.1-MM Papers Williams et al. 2017 The Met Office Global Coupled Model 3.0 and 3.1 (GC3.0 and GC3.1) Configurations Menary et al. 2018 Preindustrial Control Simulations With HadGEM3-GC3.1 for CMIP6 Andrews et al. 2020 Historical Simulations With HadGEM3-GC3.1 for CMIP6 Lai et al. 2022 Mechanisms of Internal Atlantic Multidecadal Variability in HadGEM3-GC3.1 at Two Different Resolutions","title":"Data"},{"location":"data/#data","text":"The CANARI-LE has now completed running on ARCHER2. The CANARI-LE consists of 40 ensemble members of both the CMIP6 historical simulation and SSP3-7.0. Data is stored on tape in JASMIN and priority data in stored on the JASMIN CANARI group workspace (gws).","title":"Data"},{"location":"data/#ensemble-details","text":"Model: HadGEM3-GC1.3-MM, same configuration as used in CMIP6, global configuration version 3.1 Ocean: NEMO3.6 Atmosphere: UM Sea Ice: CICE Land: Jules 40 historical (1950-2014) ensemble members 40 future projection, SSP3-7.0 (2015-2100) ensemble members More information on the CANARI-LE can be found here .","title":"Ensemble Details"},{"location":"data/#data-access","text":"To access the CANARI-LE data available on JASMIN you need to apply for access to the CANARI gws through the JASMIN accounts portal under the my services button. CANARI-LE data can be found here (/gws/nopw/j04/canari/shared/large-ensemble/priority/). HIST2 contains the 40 historical ensemble members, 1950-2014, SSP370 the future projection ensemble members, 2015-2100, and HIST1 are the 4 historical ensemble members which were part of CMIP6, 1850-2014. The list of priority variables are on this spreadsheet . You can find the long names for the variables and the short names used in the netcdf files. Please pay particular attention to the notes in red.","title":"Data Access"},{"location":"data/#useful-files","text":"For the ocean the mesh_mask and subbasins files can be found in the CANARI gws here /gws/nopw/j04/canari/shared/large-ensemble/ocean","title":"Useful Files"},{"location":"data/#how-to-cite","text":"There is no specific paper yet on the large ensemble, so please reference the HadGEM3.1 paper ( Williams et al. 2017 ) and acknowledge CANARI and JASMIN.","title":"How to cite"},{"location":"data/#hadgem3-gc31-mm-papers","text":"Williams et al. 2017 The Met Office Global Coupled Model 3.0 and 3.1 (GC3.0 and GC3.1) Configurations Menary et al. 2018 Preindustrial Control Simulations With HadGEM3-GC3.1 for CMIP6 Andrews et al. 2020 Historical Simulations With HadGEM3-GC3.1 for CMIP6 Lai et al. 2022 Mechanisms of Internal Atlantic Multidecadal Variability in HadGEM3-GC3.1 at Two Different Resolutions","title":"HadGEM3-GC3.1-MM Papers"},{"location":"git_tutorial/","text":"Collaborating with Github A quick background git init - initalise a Git repository git add - adds new changes to the staging area git commit - commits changes in the staging area to the repository git log - show list of commits git push - pushes commits to a remote (e.g. github) git pull - pulls changes from a remote Collaborating with Github Github allows multiple people to work on the same code. Multiple Collaborators to One Repository The Owner needs to give the Collaborator access. In your repository page on GitHub, click the \"Settings\" button on the right, select \"Collaborators\", click \"Add people\", and then enter your partner's username. To accept access to the Owner's repo, the Collaborator needs to go to https://github.com/notifications or check for email notification. Once there she can accept access to the Owner's repo. Next, the Collaborator needs to download a copy of the Owner's repository to her machine. This is called \"cloning a repo\". We'll be using a repository with an example script for making some plots of Sea Surface Temperature from the CANARI data. You can find this repository at https://github.com/CANARI-sprint/git-tutorial To clone the repo into her Desktop folder, the Collaborator enters: $ git clone git@github.com:CANARI-sprint/git-tutorial.git ~/Desktop/git-tutorial If you choose to clone without the clone path ( ~/Desktop/git-tutorial ) specified at the end, you will clone inside your own favourite-places folder! Make sure to navigate to the Desktop folder first. The Collaborator can now make a change in her clone of the Owner's repository: $ cd ~/Desktop/git-tutorial $ nano basic-plots.py Change: cmap = plt.get_cmap('seismic',21) To: cmap = plt.get_cmap('bwr',21) $ git add basic_plots.py $ git commit -m \"Changing the colourmap\" 1 file changed, 1 insertion(+) create mode 100644 basic_plots.py Then push the change to the Owner's repository on GitHub: $ git push origin main Enumerating objects: 4, done. Counting objects: 4, done. Delta compression using up to 4 threads. Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 306 bytes, done. Total 3 (delta 0), reused 0 (delta 0) To git@github.com:CANARI-sprint/git-tutorial.git 9272da5..29aba7c main -> main Note that we didn't have to create a remote called origin : Git uses this name by default when we clone a repository. (This is why origin was a sensible choice earlier when we were setting up remotes by hand.) Take a look at the Owner's repository on GitHub again, and you should be able to see the new commit made by the Collaborator. You may need to refresh your browser to see the new commit. To download the Collaborator's changes from GitHub, the Owner now enters: $ git pull origin main remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. From git@github.com:CANARI-sprint/git-tutorial * branch main -> FETCH_HEAD 9272da5..29aba7c main -> origin/main Updating 9272da5..29aba7c Fast-forward basic_plots.py | 1 + 1 file changed, 1 insertion(+) create mode 100644 basic_plots.py Now the three repositories (Owner's local, Collaborator's local, and Owner's on GitHub) are back in sync. Triggering a Merge Conflict If two more changes are made by doing the following: (simultaneously) Clone the repository git@github.com:CANARI-sprint/git-tutorial.git (using SSH). Edit the colourmap on line 73, choosing one from the Matplotlib Documentation . Add/Commit this change to your local repository. Push your changes to the upstream repository. Only the first person to push will be able to get their changes through, the other person will get a merge conflict error since multiple people have edited the same line. Resolving a Merge Conflict As soon as people can work in parallel, they'll likely step on each other's toes. This will even happen with a single person: if we are working on a piece of software on both our laptop and a server in the lab, we could make different changes to each copy. When the second person tries to push changes to Github they will see something like this error: To git@github.com:CANARI-sprint/git-tutorial.git ! [rejected] main -> main (fetch first) error: failed to push some refs to 'git@github.com:CANARI-sprint/git-tutorial.git' hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details. Git rejects the push because it detects that the remote repository has new updates that have not been incorporated into the local branch. What we have to do is pull the changes from GitHub, then into the copy we're currently working in, and then push that. Let's start by pulling: $ git pull origin main remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (1/1), done. remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 Unpacking objects: 100% (3/3), done. From git@github.com:CANARI-sprint/git-tutorial.git * branch main -> FETCH_HEAD 29aba7c..dabb4c8 main -> origin/main Auto-merging basic_plots.py CONFLICT (content): Merge conflict in basic_plots.py Automatic merge failed; fix conflicts and then commit the result. The git pull command updates the local repository to include those changes already included in the remote repository. After the changes from remote branch have been fetched, Git detects that changes made to the local copy overlap with those made to the remote repository, and therefore refuses to merge the two versions to stop us from trampling on our previous work. The conflict is marked in in the affected file: $ cat basic_plots.py <<<<<<< HEAD cmap = plt.get_cmap('seismic',21) ======= cmap = plt.get_cmap('PuOr',21) >>>>>>> dabb4c8c450e8475aee9b14b4383acc99f42af1d Our change is preceded by <<<<<<< HEAD . Git has then inserted ======= as a separator between the conflicting changes and marked the end of the content downloaded from GitHub with >>>>>>> . (The string of letters and digits after that marker identifies the commit we've just downloaded.) It is now up to us to edit this file to remove these markers and reconcile the changes. We can do anything we want: keep the change made in the local repository, keep the change made in the remote repository, write something new to replace both, or get rid of the change entirely. To finish merging, we add basic_plots.py to the changes being made by the merge and then commit: $ git add basic_plots.py $ git status On branch main All conflicts fixed but you are still merging. (use \"git commit\" to conclude merge) Changes to be committed: modified: basic_plots.py $ git commit -m \"Merge changes from GitHub\" [main 2abf2b1] Merge changes from GitHub Now we can push our changes to GitHub: $ git push origin main Enumerating objects: 10, done. Counting objects: 100% (10/10), done. Delta compression using up to 8 threads Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 645 bytes | 645.00 KiB/s, done. Total 6 (delta 4), reused 0 (delta 0) remote: Resolving deltas: 100% (4/4), completed with 2 local objects. To git@github.com:CANARI-sprint/git-tutorial.git dabb4c8..2abf2b1 main -> main Git keeps track of what we've merged with what, so we don't have to fix things by hand again when the collaborator who made the first change pulls again: $ git pull origin main remote: Enumerating objects: 10, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (2/2), done. remote: Total 6 (delta 4), reused 6 (delta 4), pack-reused 0 Unpacking objects: 100% (6/6), done. From git@github.com:CANARI-sprint/git-tutorial.git * branch main -> FETCH_HEAD dabb4c8..2abf2b1 main -> origin/main Updating dabb4c8..2abf2b1 Fast-forward basic_plots.py | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) Git's ability to resolve conflicts is very useful, but conflict resolution costs time and effort, and can introduce errors if conflicts are not resolved correctly. If you find yourself resolving a lot of conflicts in a project, consider these technical approaches to reducing them: Pull from upstream more frequently, especially before starting new work Use topic branches to segregate work, merging to main when complete Make smaller more atomic commits Push your work when it is done and encourage your team to do the same to reduce work in progress and, by extension, the chance of having conflicts Where logically appropriate, break large files into smaller ones so that it is less likely that two authors will alter the same file simultaneously Conflicts can also be minimized with project management strategies: Clarify who is responsible for what areas with your collaborators Discuss what order tasks should be carried out in with your collaborators so that tasks expected to change the same lines won't be worked on simultaneously If the conflicts are stylistic churn (e.g. tabs vs. spaces), establish a project convention that is governing and use code style tools (e.g. htmltidy , perltidy , rubocop , etc.) to enforce, if necessary Pull Requests As you have seen, multiple people working on the same repository can cause a lot of problems. Github provides another way to collaborate called pull requests. In these each person makes their own copy of the repository on Github, this is known as a fork. Instead of working in the same repository as everyone else, each person works on their own fork. When they are ready to send the changes back to the main repository they create a pull request (literally asking the owner of the repository to do a git pull from theirs). Github wraps this in a nice interface, which allows you to write a comment about what you changed, for the owner to review your changes (and possibly request you make more before they accept it) and for them to finally accept or reject them. Once they are accepted the changes from your fork are merged into the upstream repository. If there are any conflicts then it will be up to the owner of the upstream repository to resolve them. Pull Requesting Changes Create a fork of the favourite-places repository by visiting https://github.com/CANARI-sprint/git-tutorial and clicking on the fork link near the top right hand corner. Create an additional change to the basic_plots.py file in the repository. Github should now tell you that your fork is \"1 commit ahead\" of the upstream repository and offer a \"Contribute\" button to start the pull request. Click this and choose \"Open Pull Request\". The next screen will highlight the differences between your version and the upstream one. Go ahead and click \"Create pull request\". The repository owner should now get an alert about your pull request and can choose whether to merge it or not. Pull requests are best for larger projects where you want to control or at least review any changes. This does require the project's owners to spend time reviewing any pull requests. Smaller projects where all the developers trust each other might be better suited to allowing multiple people direct write access. Making additional changes to a Pull Request Create another pull request using the same method as above. After submitting the pull request, you decide to make another change either because you found a mistake or the upstream repository owner asked you to fix something. Make this change to your fork and push them to github. The pull request should automatically update with any additional changes you make. Pull Requests in Big Projects In many large projects all work will be done via pull requests and merging changes back into the main repository will involve a large scale code review process. There may also be autoamted checks involved to stop code which doesn't pass tests (or doesn't have tests) from being merged into a production system. Summary Conflicts occur when two or more people change the same lines of the same file. The version control system does not allow people to overwrite each other's changes blindly, but highlights conflicts so that they can be resolved. Giving many people write access to the same repository can result in a lot of conflicts if they all change the same file(s). Pull requests offer a controlled way to share your changes and let the project owner review them.","title":"Collaborating with Github"},{"location":"git_tutorial/#collaborating-with-github","text":"","title":"Collaborating with Github"},{"location":"git_tutorial/#a-quick-background","text":"git init - initalise a Git repository git add - adds new changes to the staging area git commit - commits changes in the staging area to the repository git log - show list of commits git push - pushes commits to a remote (e.g. github) git pull - pulls changes from a remote","title":"A quick background"},{"location":"git_tutorial/#collaborating-with-github_1","text":"Github allows multiple people to work on the same code.","title":"Collaborating with Github"},{"location":"git_tutorial/#multiple-collaborators-to-one-repository","text":"The Owner needs to give the Collaborator access. In your repository page on GitHub, click the \"Settings\" button on the right, select \"Collaborators\", click \"Add people\", and then enter your partner's username. To accept access to the Owner's repo, the Collaborator needs to go to https://github.com/notifications or check for email notification. Once there she can accept access to the Owner's repo. Next, the Collaborator needs to download a copy of the Owner's repository to her machine. This is called \"cloning a repo\". We'll be using a repository with an example script for making some plots of Sea Surface Temperature from the CANARI data. You can find this repository at https://github.com/CANARI-sprint/git-tutorial To clone the repo into her Desktop folder, the Collaborator enters: $ git clone git@github.com:CANARI-sprint/git-tutorial.git ~/Desktop/git-tutorial If you choose to clone without the clone path ( ~/Desktop/git-tutorial ) specified at the end, you will clone inside your own favourite-places folder! Make sure to navigate to the Desktop folder first. The Collaborator can now make a change in her clone of the Owner's repository: $ cd ~/Desktop/git-tutorial $ nano basic-plots.py Change: cmap = plt.get_cmap('seismic',21) To: cmap = plt.get_cmap('bwr',21) $ git add basic_plots.py $ git commit -m \"Changing the colourmap\" 1 file changed, 1 insertion(+) create mode 100644 basic_plots.py Then push the change to the Owner's repository on GitHub: $ git push origin main Enumerating objects: 4, done. Counting objects: 4, done. Delta compression using up to 4 threads. Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 306 bytes, done. Total 3 (delta 0), reused 0 (delta 0) To git@github.com:CANARI-sprint/git-tutorial.git 9272da5..29aba7c main -> main Note that we didn't have to create a remote called origin : Git uses this name by default when we clone a repository. (This is why origin was a sensible choice earlier when we were setting up remotes by hand.) Take a look at the Owner's repository on GitHub again, and you should be able to see the new commit made by the Collaborator. You may need to refresh your browser to see the new commit. To download the Collaborator's changes from GitHub, the Owner now enters: $ git pull origin main remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. From git@github.com:CANARI-sprint/git-tutorial * branch main -> FETCH_HEAD 9272da5..29aba7c main -> origin/main Updating 9272da5..29aba7c Fast-forward basic_plots.py | 1 + 1 file changed, 1 insertion(+) create mode 100644 basic_plots.py Now the three repositories (Owner's local, Collaborator's local, and Owner's on GitHub) are back in sync.","title":"Multiple Collaborators to One Repository"},{"location":"git_tutorial/#triggering-a-merge-conflict","text":"If two more changes are made by doing the following: (simultaneously) Clone the repository git@github.com:CANARI-sprint/git-tutorial.git (using SSH). Edit the colourmap on line 73, choosing one from the Matplotlib Documentation . Add/Commit this change to your local repository. Push your changes to the upstream repository. Only the first person to push will be able to get their changes through, the other person will get a merge conflict error since multiple people have edited the same line.","title":"Triggering a Merge Conflict"},{"location":"git_tutorial/#resolving-a-merge-conflict","text":"As soon as people can work in parallel, they'll likely step on each other's toes. This will even happen with a single person: if we are working on a piece of software on both our laptop and a server in the lab, we could make different changes to each copy. When the second person tries to push changes to Github they will see something like this error: To git@github.com:CANARI-sprint/git-tutorial.git ! [rejected] main -> main (fetch first) error: failed to push some refs to 'git@github.com:CANARI-sprint/git-tutorial.git' hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details. Git rejects the push because it detects that the remote repository has new updates that have not been incorporated into the local branch. What we have to do is pull the changes from GitHub, then into the copy we're currently working in, and then push that. Let's start by pulling: $ git pull origin main remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (1/1), done. remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 Unpacking objects: 100% (3/3), done. From git@github.com:CANARI-sprint/git-tutorial.git * branch main -> FETCH_HEAD 29aba7c..dabb4c8 main -> origin/main Auto-merging basic_plots.py CONFLICT (content): Merge conflict in basic_plots.py Automatic merge failed; fix conflicts and then commit the result. The git pull command updates the local repository to include those changes already included in the remote repository. After the changes from remote branch have been fetched, Git detects that changes made to the local copy overlap with those made to the remote repository, and therefore refuses to merge the two versions to stop us from trampling on our previous work. The conflict is marked in in the affected file: $ cat basic_plots.py <<<<<<< HEAD cmap = plt.get_cmap('seismic',21) ======= cmap = plt.get_cmap('PuOr',21) >>>>>>> dabb4c8c450e8475aee9b14b4383acc99f42af1d Our change is preceded by <<<<<<< HEAD . Git has then inserted ======= as a separator between the conflicting changes and marked the end of the content downloaded from GitHub with >>>>>>> . (The string of letters and digits after that marker identifies the commit we've just downloaded.) It is now up to us to edit this file to remove these markers and reconcile the changes. We can do anything we want: keep the change made in the local repository, keep the change made in the remote repository, write something new to replace both, or get rid of the change entirely. To finish merging, we add basic_plots.py to the changes being made by the merge and then commit: $ git add basic_plots.py $ git status On branch main All conflicts fixed but you are still merging. (use \"git commit\" to conclude merge) Changes to be committed: modified: basic_plots.py $ git commit -m \"Merge changes from GitHub\" [main 2abf2b1] Merge changes from GitHub Now we can push our changes to GitHub: $ git push origin main Enumerating objects: 10, done. Counting objects: 100% (10/10), done. Delta compression using up to 8 threads Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 645 bytes | 645.00 KiB/s, done. Total 6 (delta 4), reused 0 (delta 0) remote: Resolving deltas: 100% (4/4), completed with 2 local objects. To git@github.com:CANARI-sprint/git-tutorial.git dabb4c8..2abf2b1 main -> main Git keeps track of what we've merged with what, so we don't have to fix things by hand again when the collaborator who made the first change pulls again: $ git pull origin main remote: Enumerating objects: 10, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (2/2), done. remote: Total 6 (delta 4), reused 6 (delta 4), pack-reused 0 Unpacking objects: 100% (6/6), done. From git@github.com:CANARI-sprint/git-tutorial.git * branch main -> FETCH_HEAD dabb4c8..2abf2b1 main -> origin/main Updating dabb4c8..2abf2b1 Fast-forward basic_plots.py | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) Git's ability to resolve conflicts is very useful, but conflict resolution costs time and effort, and can introduce errors if conflicts are not resolved correctly. If you find yourself resolving a lot of conflicts in a project, consider these technical approaches to reducing them: Pull from upstream more frequently, especially before starting new work Use topic branches to segregate work, merging to main when complete Make smaller more atomic commits Push your work when it is done and encourage your team to do the same to reduce work in progress and, by extension, the chance of having conflicts Where logically appropriate, break large files into smaller ones so that it is less likely that two authors will alter the same file simultaneously Conflicts can also be minimized with project management strategies: Clarify who is responsible for what areas with your collaborators Discuss what order tasks should be carried out in with your collaborators so that tasks expected to change the same lines won't be worked on simultaneously If the conflicts are stylistic churn (e.g. tabs vs. spaces), establish a project convention that is governing and use code style tools (e.g. htmltidy , perltidy , rubocop , etc.) to enforce, if necessary","title":"Resolving a Merge Conflict"},{"location":"git_tutorial/#pull-requests","text":"As you have seen, multiple people working on the same repository can cause a lot of problems. Github provides another way to collaborate called pull requests. In these each person makes their own copy of the repository on Github, this is known as a fork. Instead of working in the same repository as everyone else, each person works on their own fork. When they are ready to send the changes back to the main repository they create a pull request (literally asking the owner of the repository to do a git pull from theirs). Github wraps this in a nice interface, which allows you to write a comment about what you changed, for the owner to review your changes (and possibly request you make more before they accept it) and for them to finally accept or reject them. Once they are accepted the changes from your fork are merged into the upstream repository. If there are any conflicts then it will be up to the owner of the upstream repository to resolve them.","title":"Pull Requests"},{"location":"git_tutorial/#pull-requesting-changes","text":"Create a fork of the favourite-places repository by visiting https://github.com/CANARI-sprint/git-tutorial and clicking on the fork link near the top right hand corner. Create an additional change to the basic_plots.py file in the repository. Github should now tell you that your fork is \"1 commit ahead\" of the upstream repository and offer a \"Contribute\" button to start the pull request. Click this and choose \"Open Pull Request\". The next screen will highlight the differences between your version and the upstream one. Go ahead and click \"Create pull request\". The repository owner should now get an alert about your pull request and can choose whether to merge it or not. Pull requests are best for larger projects where you want to control or at least review any changes. This does require the project's owners to spend time reviewing any pull requests. Smaller projects where all the developers trust each other might be better suited to allowing multiple people direct write access.","title":"Pull Requesting Changes"},{"location":"git_tutorial/#making-additional-changes-to-a-pull-request","text":"Create another pull request using the same method as above. After submitting the pull request, you decide to make another change either because you found a mistake or the upstream repository owner asked you to fix something. Make this change to your fork and push them to github. The pull request should automatically update with any additional changes you make.","title":"Making additional changes to a Pull Request"},{"location":"git_tutorial/#pull-requests-in-big-projects","text":"In many large projects all work will be done via pull requests and merging changes back into the main repository will involve a large scale code review process. There may also be autoamted checks involved to stop code which doesn't pass tests (or doesn't have tests) from being merged into a production system.","title":"Pull Requests in Big Projects"},{"location":"git_tutorial/#summary","text":"Conflicts occur when two or more people change the same lines of the same file. The version control system does not allow people to overwrite each other's changes blindly, but highlights conflicts so that they can be resolved. Giving many people write access to the same repository can result in a lot of conflicts if they all change the same file(s). Pull requests offer a controlled way to share your changes and let the project owner review them.","title":"Summary"},{"location":"github/","text":"Git Setup and Basics About Git and GitHub Git is a popular version control system that is the foundation of most open source software development. You are not required to be a Git pro in advance of this event, but come prepared to learn a lot about it! GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment. We will use Git and GitHub for collaborative work. Git Installation Windows Install Git for Windows from this link . For more setup details follow these instructions Mac OS Download the git installer and run it. Linux (Debian/Ubuntu): sudo apt install git-all To test, open the terminal (on Windows, Git Bash) and setup your username and email: git config --global user.name \"your username\" git config --global user.email \"your email\" Getting started with Bash terminal During the CANARI-Sprint week it will be useful to know how to navigate between files from the command line. If you are not familiar with the linux shell commands, you can review the first three sections of this Software Carpentry Shell Novice lesson. On Windows, use the Git Bash terminal to run these commands. Terminal (command line) text editor When working on the command line (the terminal or shell), it is often handy to modify file content directly from there. For that you can use a command line editor such as nano . On Mac and Linux it is usually pre-installed, and on Windows it is installed when you install Git (see here for more information about nano and its configuration). Test your installation by opening a terminal and running nano --version . If it works you can link your git configuration with nano : git config --global core.editor \"nano -w\" Git steps and workflows 1. Create a project repository On your own or someone in your project group (preferably one who has done it before), create a repository for the project under the CANARI-sprint organization, https://github.com/CANARI-sprint Click New and follow the steps: check yes to create a README.md file. Format project name as proj-myprojectname (you can change the name later), where myprojectname is a brief name for your project Invite others to the repo: Settings -> Collaborators Note to collaborators: you will receive an invitation to your email associated with github.com. If you cannnot find it look for the bell notifications on the top right of the website. 2. Clone the repository Each participant should clone the repository so they have their copy on their JupyterHub account space (and locally in the participant's computer, if desired). Navigate through the terminal to the folder where you want to keep CANARI-Sprint work ( cd path_to_canari-sprint-work ). git clone https://github.com/CANARI-Sprint/proj-myprojectname.git This will create a new folder called proj-myprojectname . Navigate ( cd ) to this new folder. 3. Update the README with your name Open the README.md file with your favorite editor and create a new section header. Under this section add your name. Then add this change, commit it to the local repository, and push it so that it appears on the origin GitHub repository. git add README.md git commit -m \"Adding new name to README.md\" git push origin Make sure your change appears online. Remember to run git status to observe the changes made into your repository. Pay attention to the colors. To see the changes in the files run git diff . 4. Update your local repository (local clone) with the changes of your collaborators git pull origin main Short names for repositories: : Remember origin is just a short name of the web address of the repository. To see what is hidden in origin: git remote -v To continue practicing these steps, make more changes to the title and the description of the project. Ran into a problem? !ATTENTION When working with several people sometimes you Cannot push because changes have been made that have not been incorporated: need to first pull When pulling you arrive into a merge conflict: need to resolve the conflict manually #### 5. Resolving the merge conflict ```bash git status You will see the file(s) which caused the merge conflict in green. Open it and detect the conflict by the special format: <<<<<<< HEAD my text ======= somebody else's text >>>>>>> 35ab35436 Decide which changes you want to keep, and modify the file so it looks as you wish directly from the editor. Remove the unnecessary characters. Add, commit and push the changes. git add README.md git commit -m \"resolving merge conflict\" git push origin main You can continue working on as usual. Remember to pull often and push small changes ... to avoid messing with complicated merges and keep your repo up-to-date. Troubleshooting Deleting files git rm filename.txt rm filename.txt Note : git rm just removes the file from git, to delete the file completely use the bash rm command after that. Reverting to the previous commit git revert HEAD Note : Your files in the local repo will still be there. References and Resources Git and GitHub are very powerful tools but no doubt the learning curve is steep. Learning is an iterative process so below we list some resources which can help you be better prepared: git-novice - Software Carpentry Lesson (3 hours with exercises) Setting Up Git - Software Carpentry Lesson Atlassian Tutorials - Version Control An excellent guide to the Forking Git Workflow: Step-by-step guide to contributing on GitHub What is GitHub? (3:45 min) GitHub Learning Lab : practice with a bot! (On your own pace) An interactive Git Tutorial: the tool you didn\u2019t know you needed. From personal workflows to open collaboration GeoHackWeek 2019 tutorial: Getting started with Git ICESAT-2HackWeek intro-jupyter-git repo , with several notebooks going into a lot of detail.","title":"Github"},{"location":"github/#git-setup-and-basics","text":"","title":"Git Setup and Basics"},{"location":"github/#about-git-and-github","text":"Git is a popular version control system that is the foundation of most open source software development. You are not required to be a Git pro in advance of this event, but come prepared to learn a lot about it! GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment. We will use Git and GitHub for collaborative work.","title":"About Git and GitHub"},{"location":"github/#git-installation","text":"Windows Install Git for Windows from this link . For more setup details follow these instructions Mac OS Download the git installer and run it. Linux (Debian/Ubuntu): sudo apt install git-all To test, open the terminal (on Windows, Git Bash) and setup your username and email: git config --global user.name \"your username\" git config --global user.email \"your email\"","title":"Git Installation"},{"location":"github/#getting-started-with-bash-terminal","text":"During the CANARI-Sprint week it will be useful to know how to navigate between files from the command line. If you are not familiar with the linux shell commands, you can review the first three sections of this Software Carpentry Shell Novice lesson. On Windows, use the Git Bash terminal to run these commands.","title":"Getting started with Bash terminal"},{"location":"github/#terminal-command-line-text-editor","text":"When working on the command line (the terminal or shell), it is often handy to modify file content directly from there. For that you can use a command line editor such as nano . On Mac and Linux it is usually pre-installed, and on Windows it is installed when you install Git (see here for more information about nano and its configuration). Test your installation by opening a terminal and running nano --version . If it works you can link your git configuration with nano : git config --global core.editor \"nano -w\"","title":"Terminal (command line) text editor"},{"location":"github/#git-steps-and-workflows","text":"","title":"Git steps and workflows"},{"location":"github/#1-create-a-project-repository","text":"On your own or someone in your project group (preferably one who has done it before), create a repository for the project under the CANARI-sprint organization, https://github.com/CANARI-sprint Click New and follow the steps: check yes to create a README.md file. Format project name as proj-myprojectname (you can change the name later), where myprojectname is a brief name for your project Invite others to the repo: Settings -> Collaborators Note to collaborators: you will receive an invitation to your email associated with github.com. If you cannnot find it look for the bell notifications on the top right of the website.","title":"1. Create a project repository"},{"location":"github/#2-clone-the-repository","text":"Each participant should clone the repository so they have their copy on their JupyterHub account space (and locally in the participant's computer, if desired). Navigate through the terminal to the folder where you want to keep CANARI-Sprint work ( cd path_to_canari-sprint-work ). git clone https://github.com/CANARI-Sprint/proj-myprojectname.git This will create a new folder called proj-myprojectname . Navigate ( cd ) to this new folder.","title":"2. Clone the repository"},{"location":"github/#3-update-the-readme-with-your-name","text":"Open the README.md file with your favorite editor and create a new section header. Under this section add your name. Then add this change, commit it to the local repository, and push it so that it appears on the origin GitHub repository. git add README.md git commit -m \"Adding new name to README.md\" git push origin Make sure your change appears online. Remember to run git status to observe the changes made into your repository. Pay attention to the colors. To see the changes in the files run git diff .","title":"3. Update the README with your name"},{"location":"github/#4-update-your-local-repository-local-clone-with-the-changes-of-your-collaborators","text":"git pull origin main Short names for repositories: : Remember origin is just a short name of the web address of the repository. To see what is hidden in origin: git remote -v To continue practicing these steps, make more changes to the title and the description of the project. Ran into a problem? !ATTENTION When working with several people sometimes you Cannot push because changes have been made that have not been incorporated: need to first pull When pulling you arrive into a merge conflict: need to resolve the conflict manually #### 5. Resolving the merge conflict ```bash git status You will see the file(s) which caused the merge conflict in green. Open it and detect the conflict by the special format: <<<<<<< HEAD my text ======= somebody else's text >>>>>>> 35ab35436 Decide which changes you want to keep, and modify the file so it looks as you wish directly from the editor. Remove the unnecessary characters. Add, commit and push the changes. git add README.md git commit -m \"resolving merge conflict\" git push origin main You can continue working on as usual. Remember to pull often and push small changes ... to avoid messing with complicated merges and keep your repo up-to-date.","title":"4. Update your local repository (local clone) with the changes of your collaborators"},{"location":"github/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"github/#deleting-files","text":"git rm filename.txt rm filename.txt Note : git rm just removes the file from git, to delete the file completely use the bash rm command after that.","title":"Deleting files"},{"location":"github/#reverting-to-the-previous-commit","text":"git revert HEAD Note : Your files in the local repo will still be there.","title":"Reverting to the previous commit"},{"location":"github/#references-and-resources","text":"Git and GitHub are very powerful tools but no doubt the learning curve is steep. Learning is an iterative process so below we list some resources which can help you be better prepared: git-novice - Software Carpentry Lesson (3 hours with exercises) Setting Up Git - Software Carpentry Lesson Atlassian Tutorials - Version Control An excellent guide to the Forking Git Workflow: Step-by-step guide to contributing on GitHub What is GitHub? (3:45 min) GitHub Learning Lab : practice with a bot! (On your own pace) An interactive Git Tutorial: the tool you didn\u2019t know you needed. From personal workflows to open collaboration GeoHackWeek 2019 tutorial: Getting started with Git ICESAT-2HackWeek intro-jupyter-git repo , with several notebooks going into a lot of detail.","title":"References and Resources"},{"location":"highlights/","text":"Highlights March 2025 If you have any plots you would like to see featured on this page or present during a highlights session please post a message to the #epesc-leader-lesfmip-sprint channel! We'll then add them here at the end of the day. Updates begin March 17, 2025! Have a great plot from your analysis today? Drop it into the Slack #epesc-leader-lesfmip-sprint channel! We'll then add them here at the end of the day. Day 1","title":"Highlights"},{"location":"highlights/#highlights","text":"","title":"Highlights"},{"location":"highlights/#march-2025","text":"If you have any plots you would like to see featured on this page or present during a highlights session please post a message to the #epesc-leader-lesfmip-sprint channel! We'll then add them here at the end of the day. Updates begin March 17, 2025! Have a great plot from your analysis today? Drop it into the Slack #epesc-leader-lesfmip-sprint channel! We'll then add them here at the end of the day. Day 1","title":"March 2025"},{"location":"jasmin_notebook_service/","text":"Configuring and Using the JASMIN Notebooks Service Logging into the JASMIN Notebook Service In your web browser visit https://notebooks.jasmin.ac.uk Login using your JASMIN username and password You will then be emailed a one time code, paste this into the verification code box. A Jupyter notebook interface will now be started and you can create a new notebook or open a terminal. Your JASMIN home directory and group workspaces will be accessible from within the notebook environment. Setting up the CANARI Conda Environment We have preconfigured a CANARI conda environment for you to use. This contains many (but perhaps not all) of the packages you are likely to need. It is built using the environment.yml file that can be found in the CANARI tutorials github . The environment is located on the Group Work Space under the path /gws/smf/j04/canari/conda-env , because it is held in a non-standard location your Jupyter notebooks won't find it automatically. In order to use it do the following: From the Jupyter launcher click on the terminal icon Type: conda run -p /gws/smf/j04/canari/conda-env python -m ipykernel install --user --name CANARI and press enter Open a new Jupyter launcher by clicking on File and then New Launcher There should now be a notebook and console option called CANARI, although this can take around one minute to appear. Getting the CANARI example code First ensure you are in your home directory by clicking on the folder icon in the file browser on the left side of the screen. Click on the Git menu and choose \"Clone a repo\" Enter https://github.com/CANARI-sprint/tutorials as the URI of the remote Git repository. Click Clone This will create a copy of the repository from https://github.com/CANARI-sprint/tutorials into your JASMIN home directory. Open and run an example notebook Click on the tutorials folder that contains your clone of the github repository. Open the notebooks folder. Choose the 1_basic_manipulation.ipynb notebook If you are asked which kernel you would like to use choose the CANARI kernel. Test the notebook can run by clicking on the Run menu and choosing \"Run all cells\" or going through each cell one by one and clicking the play button.","title":"Jasmin notebook service"},{"location":"jasmin_notebook_service/#configuring-and-using-the-jasmin-notebooks-service","text":"","title":"Configuring and Using the JASMIN Notebooks Service"},{"location":"jasmin_notebook_service/#logging-into-the-jasmin-notebook-service","text":"In your web browser visit https://notebooks.jasmin.ac.uk Login using your JASMIN username and password You will then be emailed a one time code, paste this into the verification code box. A Jupyter notebook interface will now be started and you can create a new notebook or open a terminal. Your JASMIN home directory and group workspaces will be accessible from within the notebook environment.","title":"Logging into the JASMIN Notebook Service"},{"location":"jasmin_notebook_service/#setting-up-the-canari-conda-environment","text":"We have preconfigured a CANARI conda environment for you to use. This contains many (but perhaps not all) of the packages you are likely to need. It is built using the environment.yml file that can be found in the CANARI tutorials github . The environment is located on the Group Work Space under the path /gws/smf/j04/canari/conda-env , because it is held in a non-standard location your Jupyter notebooks won't find it automatically. In order to use it do the following: From the Jupyter launcher click on the terminal icon Type: conda run -p /gws/smf/j04/canari/conda-env python -m ipykernel install --user --name CANARI and press enter Open a new Jupyter launcher by clicking on File and then New Launcher There should now be a notebook and console option called CANARI, although this can take around one minute to appear.","title":"Setting up the CANARI Conda Environment"},{"location":"jasmin_notebook_service/#getting-the-canari-example-code","text":"First ensure you are in your home directory by clicking on the folder icon in the file browser on the left side of the screen. Click on the Git menu and choose \"Clone a repo\" Enter https://github.com/CANARI-sprint/tutorials as the URI of the remote Git repository. Click Clone This will create a copy of the repository from https://github.com/CANARI-sprint/tutorials into your JASMIN home directory.","title":"Getting the CANARI example code"},{"location":"jasmin_notebook_service/#open-and-run-an-example-notebook","text":"Click on the tutorials folder that contains your clone of the github repository. Open the notebooks folder. Choose the 1_basic_manipulation.ipynb notebook If you are asked which kernel you would like to use choose the CANARI kernel. Test the notebook can run by clicking on the Run menu and choosing \"Run all cells\" or going through each cell one by one and clicking the play button.","title":"Open and run an example notebook"},{"location":"running_on_sci_servers/","text":"Running on the JASMIN Sci Servers The JASMIN notebook service only has limited resources and might not be sufficient for some larger datasets. One alternative is to use the Sci servers. These are 7 shared servers which JASMIN users can login to and run code on. Logging on to the Sci servers First login to the JASMIN login server (replace with your own username): ssh -A <jasminusername>@login-01.jasmin.ac.uk Do not forget to add the -A option to add your SSH key to the session. Then login to one of the sci servers, there are 7 of these in total called sci-ph-01, sci-ph-02 and sci-vm-0(1 to 5). The sci-ph systems are physical servers whereas sci-vm are virtual servers. ssh sci-ph-01 Or this can all be wrapped up in one command using an SSH \"jump host\" with: ssh -J <jasminusername>@login-01.jasmin.ac.uk <jasminusername>@sci-ph-01 Activating the shared CANARI environment Conda is available on the Sci servers through the jaspy module. If this is the first time you have used conda on the sci servers, you will need to run module load jaspy followed by conda init . You'll then need to either launch a new shell session or source your .bashrc file. After this, your prompt should start with (base) . If you want to run any code in the shared CANARI environment then you need to \"activate\" that enviroment. To do this run: conda activate /gws/smf/j04/canari/conda-env Your prompt should now change to start with (/gws/smf/j04/canari/conda-env) to indicate that this environment is now active. Running a JupyterLab instance on a Sci server It is recommended that you use your own copy of CANARI environment for this. If you haven't already made one see the instructions in tutorial 3 - Creating Your Own Conda Enviroment . Assuming you ran this tutorial you should have an environment called canari , go ahead and activate this by running: micromamba activate canari JupyterLab was already started and can be run with the command: jupyter-lab This will put a lot of text onto the screen, but at the bottom it will say something like: To access the server, open this file in a browser: file:///home/users/colinsau/.local/share/jupyter/runtime/jpserver-27367-open.html Or copy and paste one of these URLs: http://localhost:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 http://127.0.0.1:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 The JupyterLab is now running on the sci server you are logged into and listening to requests on port 8889 (your port number might be different, pay attention to this!). But to connect to it we need to open another SSH session. Note that you must leave this SSH session/terminal window open, if you press ctrl+c or close it then the JupyterLab session will stop. To open another SSH session open another terminal and run: ssh -J <jasminusername>@login-01.jasmin.ac.uk -L 8889:localhost:8889 <jasminusername>@sci-ph-01 This will bring up a new terminal logged into sci-ph-01, but it will also forward requests on your own computer's port 8889 to sci-ph-01's port 8889 allowing you to access your Jupyter server on sci-ph-01. Now open a web browser and paste in one of the URLs starting \"http://\" from the output from starting JupyterLab. Shutting down your JupyterLab instance To shutdown your JupyterLab instance press the control key and c at the same time (ctrl+c) in the window where JupyterLab was running. It will ask you Shutdown this Jupyter server (y/[n])? press y and enter and then it will shutdown the JupyterLab instance.","title":"Running on sci servers"},{"location":"running_on_sci_servers/#running-on-the-jasmin-sci-servers","text":"The JASMIN notebook service only has limited resources and might not be sufficient for some larger datasets. One alternative is to use the Sci servers. These are 7 shared servers which JASMIN users can login to and run code on.","title":"Running on the JASMIN Sci Servers"},{"location":"running_on_sci_servers/#logging-on-to-the-sci-servers","text":"First login to the JASMIN login server (replace with your own username): ssh -A <jasminusername>@login-01.jasmin.ac.uk Do not forget to add the -A option to add your SSH key to the session. Then login to one of the sci servers, there are 7 of these in total called sci-ph-01, sci-ph-02 and sci-vm-0(1 to 5). The sci-ph systems are physical servers whereas sci-vm are virtual servers. ssh sci-ph-01 Or this can all be wrapped up in one command using an SSH \"jump host\" with: ssh -J <jasminusername>@login-01.jasmin.ac.uk <jasminusername>@sci-ph-01","title":"Logging on to the Sci servers"},{"location":"running_on_sci_servers/#activating-the-shared-canari-environment","text":"Conda is available on the Sci servers through the jaspy module. If this is the first time you have used conda on the sci servers, you will need to run module load jaspy followed by conda init . You'll then need to either launch a new shell session or source your .bashrc file. After this, your prompt should start with (base) . If you want to run any code in the shared CANARI environment then you need to \"activate\" that enviroment. To do this run: conda activate /gws/smf/j04/canari/conda-env Your prompt should now change to start with (/gws/smf/j04/canari/conda-env) to indicate that this environment is now active.","title":"Activating the shared CANARI environment"},{"location":"running_on_sci_servers/#running-a-jupyterlab-instance-on-a-sci-server","text":"It is recommended that you use your own copy of CANARI environment for this. If you haven't already made one see the instructions in tutorial 3 - Creating Your Own Conda Enviroment . Assuming you ran this tutorial you should have an environment called canari , go ahead and activate this by running: micromamba activate canari JupyterLab was already started and can be run with the command: jupyter-lab This will put a lot of text onto the screen, but at the bottom it will say something like: To access the server, open this file in a browser: file:///home/users/colinsau/.local/share/jupyter/runtime/jpserver-27367-open.html Or copy and paste one of these URLs: http://localhost:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 http://127.0.0.1:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 The JupyterLab is now running on the sci server you are logged into and listening to requests on port 8889 (your port number might be different, pay attention to this!). But to connect to it we need to open another SSH session. Note that you must leave this SSH session/terminal window open, if you press ctrl+c or close it then the JupyterLab session will stop. To open another SSH session open another terminal and run: ssh -J <jasminusername>@login-01.jasmin.ac.uk -L 8889:localhost:8889 <jasminusername>@sci-ph-01 This will bring up a new terminal logged into sci-ph-01, but it will also forward requests on your own computer's port 8889 to sci-ph-01's port 8889 allowing you to access your Jupyter server on sci-ph-01. Now open a web browser and paste in one of the URLs starting \"http://\" from the output from starting JupyterLab.","title":"Running a JupyterLab instance on a Sci server"},{"location":"running_on_sci_servers/#shutting-down-your-jupyterlab-instance","text":"To shutdown your JupyterLab instance press the control key and c at the same time (ctrl+c) in the window where JupyterLab was running. It will ask you Shutdown this Jupyter server (y/[n])? press y and enter and then it will shutdown the JupyterLab instance.","title":"Shutting down your JupyterLab instance"},{"location":"setup/","text":"Pre-event This page contains all the pre-event setup required to prepare you to make the most of the event. New items may appear on the list as the event gets closer. Sign-up for the event to make sure you are kept in the loop with the last information and see potential collaborators on the spreadsheet . Slack Workspace Make sure you can sign into the CANARI Slack workspace. If you don't have access to the CANARI slack space please contact Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) to send you an invite. Join the appropriate channels on the CANARI Slack workspace, all channels relevant to the sprint will be prefaced with the word 'sprint'. There are channels setup where you can get help for the sprint which will be monitored, they will be labeled starting 'sprint-help'. Feel free to add channels to help collaborate your analysis during the sprint and make sure to label them with 'sprint'. JASMIN - keep in mind it might take a few days to get your accounts approved Make sure you have a JASMIN account. If you are new to JASMIN please mention the CANARI-LE sprint in your application. Instructions on signing up for an account can be found here . If you are only planning on using JASMIN for the sprint and don't have an account please contact Jenny Mecking (jmecki@noc.ac.uk) and a temporary account can be setup. Sign-up for the required JASMIN services through the accounts portal . JASMIN log-in account CANARI group workspace (gws) (optional) Link your JASMIN account with a CEDA account. This will provide you with access to several datasets including ERA5 and CMIP data. (optional) If you want to give the dask gateway a try during the sprint you can signup on the JASMIN dask gateway page . (optional) If you want to try processing of data using GPUs you need to signup for the additional service, orchid through the JASMIN accounts portal. ZOOM - communication during the sprint will be done via zoom, please make sure you are able to connect Plan your analysis Several work packages have been actively making plans on what they would like to do. If you are unsure of what analysis you are planning on doing in the first instance speak with your work package leader and/or centre lead (you can see who this is in the sign-up spread sheet). If that fails contact someone from the signup spreadsheet with similar interests to you. Take a look at the data on JASMIN to make sure the data you want to work with is there and looks correct. The data can be found here on JASMIN: /gws/nopw/j04/canari/shared/large-ensemble/priority/ ( for more details on the data ) Shared datasets and shared analysis If you want to use any observation based dataset or other to compare the data from the CANARI-LE or already have dowloaded some datasets please fill in this spreadsheet . If you are planning on doing, would like to use or have already done some analysis that might be useful for multiple people (e.g. computing the Atlantic Multi-decadal Variability (AMV) or computing jet stream latitudes) please fill in this spreadsheet .","title":"Pre-event"},{"location":"setup/#pre-event","text":"This page contains all the pre-event setup required to prepare you to make the most of the event. New items may appear on the list as the event gets closer. Sign-up for the event to make sure you are kept in the loop with the last information and see potential collaborators on the spreadsheet . Slack Workspace Make sure you can sign into the CANARI Slack workspace. If you don't have access to the CANARI slack space please contact Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) to send you an invite. Join the appropriate channels on the CANARI Slack workspace, all channels relevant to the sprint will be prefaced with the word 'sprint'. There are channels setup where you can get help for the sprint which will be monitored, they will be labeled starting 'sprint-help'. Feel free to add channels to help collaborate your analysis during the sprint and make sure to label them with 'sprint'. JASMIN - keep in mind it might take a few days to get your accounts approved Make sure you have a JASMIN account. If you are new to JASMIN please mention the CANARI-LE sprint in your application. Instructions on signing up for an account can be found here . If you are only planning on using JASMIN for the sprint and don't have an account please contact Jenny Mecking (jmecki@noc.ac.uk) and a temporary account can be setup. Sign-up for the required JASMIN services through the accounts portal . JASMIN log-in account CANARI group workspace (gws) (optional) Link your JASMIN account with a CEDA account. This will provide you with access to several datasets including ERA5 and CMIP data. (optional) If you want to give the dask gateway a try during the sprint you can signup on the JASMIN dask gateway page . (optional) If you want to try processing of data using GPUs you need to signup for the additional service, orchid through the JASMIN accounts portal. ZOOM - communication during the sprint will be done via zoom, please make sure you are able to connect Plan your analysis Several work packages have been actively making plans on what they would like to do. If you are unsure of what analysis you are planning on doing in the first instance speak with your work package leader and/or centre lead (you can see who this is in the sign-up spread sheet). If that fails contact someone from the signup spreadsheet with similar interests to you. Take a look at the data on JASMIN to make sure the data you want to work with is there and looks correct. The data can be found here on JASMIN: /gws/nopw/j04/canari/shared/large-ensemble/priority/ ( for more details on the data ) Shared datasets and shared analysis If you want to use any observation based dataset or other to compare the data from the CANARI-LE or already have dowloaded some datasets please fill in this spreadsheet . If you are planning on doing, would like to use or have already done some analysis that might be useful for multiple people (e.g. computing the Atlantic Multi-decadal Variability (AMV) or computing jet stream latitudes) please fill in this spreadsheet .","title":"Pre-event"},{"location":"sprint/","text":"Sprint The sprint will take place January 27-31, 2025 as a hybrid sprint, with each participating centre working together and then connecting to each other via zoom. The goal of the sprint is to work together to kickstart analysis on the CANARI-LE future projection data. Useful links participants list CANARI sprint GitHub Repositories list of useful datasets on JASMIN list of analysis useful to multiple people priority variables and variable names CANARI-LE information Schedule Monday (Jan. 27): 9:45: Zoom channel opens for the day 10:00-12:30: Introduction Good morning and Welcome (chair: Jenny) Overview of CANARI (Len) CANARI-LE overview (Oscar) Event Communication Plans (Ben) Around the Zoom room Introductions (Centre Coordinators) JASMIN Support Introduction (Fatima, ? and ?) Research Software Engineer Introduction (Colin, Esther and Jonathan) Overview of the week (Jenny) 13:30-15:00: How can I help? Ensemble Member Selection for NAAC (Jo) Storylines (Hazel and Wilson) 16:30-17:00: highlights of the day (chair: David) Tuesday (Jan. 28): 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Scott) 11:00-12:00: Tips from the Research Software Engineers Coding best practices (Colin and Esther) Dask example script tutorial (Esther) 14:00: cf-python: A data analysis package designed for CANARI (David) 16:30-17:00: highlights of the day (chair: Reinhard) Wednesday (Jan. 29): 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Ben) 16:30-17:00: highlights of the day (chair: Bablu) Thursday (Jan. 30): 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Dan) 16:30-17:00: highlights of the day (chair: Len) Friday (Jan. 31): 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Xiaoyan) 16:00-17:00: highlights of the week (chair: Marilena)","title":"Sprint"},{"location":"sprint/#sprint","text":"The sprint will take place January 27-31, 2025 as a hybrid sprint, with each participating centre working together and then connecting to each other via zoom. The goal of the sprint is to work together to kickstart analysis on the CANARI-LE future projection data.","title":"Sprint"},{"location":"sprint/#useful-links","text":"participants list CANARI sprint GitHub Repositories list of useful datasets on JASMIN list of analysis useful to multiple people priority variables and variable names CANARI-LE information","title":"Useful links"},{"location":"sprint/#schedule","text":"","title":"Schedule"},{"location":"sprint/#monday-jan-27","text":"9:45: Zoom channel opens for the day 10:00-12:30: Introduction Good morning and Welcome (chair: Jenny) Overview of CANARI (Len) CANARI-LE overview (Oscar) Event Communication Plans (Ben) Around the Zoom room Introductions (Centre Coordinators) JASMIN Support Introduction (Fatima, ? and ?) Research Software Engineer Introduction (Colin, Esther and Jonathan) Overview of the week (Jenny) 13:30-15:00: How can I help? Ensemble Member Selection for NAAC (Jo) Storylines (Hazel and Wilson) 16:30-17:00: highlights of the day (chair: David)","title":"Monday (Jan. 27):"},{"location":"sprint/#tuesday-jan-28","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Scott) 11:00-12:00: Tips from the Research Software Engineers Coding best practices (Colin and Esther) Dask example script tutorial (Esther) 14:00: cf-python: A data analysis package designed for CANARI (David) 16:30-17:00: highlights of the day (chair: Reinhard)","title":"Tuesday (Jan. 28):"},{"location":"sprint/#wednesday-jan-29","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Ben) 16:30-17:00: highlights of the day (chair: Bablu)","title":"Wednesday (Jan. 29):"},{"location":"sprint/#thursday-jan-30","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Dan) 16:30-17:00: highlights of the day (chair: Len)","title":"Thursday (Jan. 30):"},{"location":"sprint/#friday-jan-31","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of highlights, known issues and good to knows (chair: Xiaoyan) 16:00-17:00: highlights of the week (chair: Marilena)","title":"Friday (Jan. 31):"},{"location":"tutorials/","text":"Tutorials Some simple tutorials to get you started analysing the CANARI-LE. Git Setup and Basics Configuring and Using the JASMIN Notebooks Service Creating and Using your Own Conda/Mamba Enviroment Running on Sci Servers, installing Micromamba and running your own JupyterLab Using the Dask gateway Computing indices with cf-python CDFTOOLS : a diagnostic package written in fortran 90 for the analysis of NEMO model output, initialized in the frame of the DRAKKAR project (https://www.drakkar-ocean.eu/) Data Analysis Guides: Access our data analysis guides hosted on the tutorials repository . Github collaborative working tutorial To try these tutorials independently, clone the repository in JASMIN with the following commands: git clone https://github.com/CANARI-sprint/tutorials.git cd tutorials !IMPORTANT: You need to have access to the CANARI gws. Here's a catalog of the available notebooks. The first 8 tutorials refer to the COAsT python package . 1) Basic Data Manipulation : Introduction to data handling using the COAsT package. 2) Exporting to NetCDF : Guide on exporting outputs to netCDF format for future use or analysis. 3) Climatology Tutorial : Demonstrates calculating climatological means and multi-year climatologies. 4) Calculating EOFs : How to utilize COAsT for computing Empirical Orthogonal Functions (EOFs). 5) Potential Energy Analysis : Tutorial on calculating Potential Energy Anomaly and applying regional masking.. 6) Pycnocline Diagnostics : Exploration of pycnocline depth and thickness diagnostics. 7) Seasonal Decomposition : Techniques for decomposing time series into trend, seasonal, and residual components. 8) Transect Calculations : Methods for creating data transects. 9) Basic Plots and Analysis : Utilizing CANARI-LE historical data for Sea Surface Temperature (SST) visualization. 10) UK Precipitation Plots : Making plots of UK precipitation using the iris python package, curtesy of Ben Harvey. 11) Box Profile Development : Computing ocean profiles with selected variables making use of the lotus queue on JASMIN.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"Some simple tutorials to get you started analysing the CANARI-LE. Git Setup and Basics Configuring and Using the JASMIN Notebooks Service Creating and Using your Own Conda/Mamba Enviroment Running on Sci Servers, installing Micromamba and running your own JupyterLab Using the Dask gateway Computing indices with cf-python CDFTOOLS : a diagnostic package written in fortran 90 for the analysis of NEMO model output, initialized in the frame of the DRAKKAR project (https://www.drakkar-ocean.eu/) Data Analysis Guides: Access our data analysis guides hosted on the tutorials repository . Github collaborative working tutorial To try these tutorials independently, clone the repository in JASMIN with the following commands: git clone https://github.com/CANARI-sprint/tutorials.git cd tutorials !IMPORTANT: You need to have access to the CANARI gws. Here's a catalog of the available notebooks. The first 8 tutorials refer to the COAsT python package . 1) Basic Data Manipulation : Introduction to data handling using the COAsT package. 2) Exporting to NetCDF : Guide on exporting outputs to netCDF format for future use or analysis. 3) Climatology Tutorial : Demonstrates calculating climatological means and multi-year climatologies. 4) Calculating EOFs : How to utilize COAsT for computing Empirical Orthogonal Functions (EOFs). 5) Potential Energy Analysis : Tutorial on calculating Potential Energy Anomaly and applying regional masking.. 6) Pycnocline Diagnostics : Exploration of pycnocline depth and thickness diagnostics. 7) Seasonal Decomposition : Techniques for decomposing time series into trend, seasonal, and residual components. 8) Transect Calculations : Methods for creating data transects. 9) Basic Plots and Analysis : Utilizing CANARI-LE historical data for Sea Surface Temperature (SST) visualization. 10) UK Precipitation Plots : Making plots of UK precipitation using the iris python package, curtesy of Ben Harvey. 11) Box Profile Development : Computing ocean profiles with selected variables making use of the lotus queue on JASMIN.","title":"Tutorials"},{"location":"using_the_dask_gateway/","text":"Using the Dask gateway What is Dask? Dask is a distributed computing framework for Python. It allows operations working on large datasets to be split across multiple computers (or multiple cores on the same computer). JASMIN offers a Dask gateway that allows jobs to run on up to 16 CPU cores on the Lotus cluster. This can be a convienient way to overcome the processor and memory limitations of the JASMIN notebook service, while still using that service to write and run your code. Requesting Access to the Dask Cluster Before using the Dask Cluster on JASMIN you must add it to your services. Please visit the additional services page on the JASMIN accounts portal This will need approval from the JASMIN staff and won't happen instantly. Configuring your Dask environment There are some extra packages that aren't in the main CANARI environment that you'll need to run Dask. We've added these to another environment in the group workspace called dask-env. To make the Dask enviroment visible to Jupyter Lab, in a terminal on the notebook service run: mamba run -p /gws/smf/j04/canari/dask-env python -m ipykernel install --user --name CANARI-dask . After about one minute a new icon called \"CANARI-dask\" should appear in the Jupyter launcher. If you have existing Dask code then see the JASMIN documentation for an example of how to configure it to use the Dask gateway or see the examples below. Running the examples There are three dask examples in the tutorials git repository. If you cloned the repository before these were added (January 28th 2025) then you'll need to run a git pull operation to bring in the latest changes. In the files view in Jupyter Lab go to your copy of tutorials repository, click on the Git menu and choose \"Pull from Remote\". Or you can navigate to this directory in the terminal and type the command git pull . Three example files called dask-example1.ipynb , dask-example2.ipynb and dask-example-xarray.ipynb should appear. Open these, ensure they are using the CANARI-dask kernel and launch them. The first example demonstrates the Dask Delayed feature where calculations are not executed until their result is requested. The second example shows the futures feature where tasks are executed immediately, but anything wanting to access to the result will be forced to wait until the calculation is complete. The third example does use the dask gateway, but doesn't use dask directly. Instead it aims to replicate a more typical use of dask for this sprint - it uses xarray , which uses dask as long as it is installed, with some CANARI data to do some basic calculations and plotting. See this page for more information about how dask is integrated in xarray. Accessing the Dask gateway from the sci servers You will need to generate a token for accessing the Dask gateway and place this in ~/.config/dask/gateway.yaml . See the JASMIN Dask documentation for details on how generate a token and the format of the config file.","title":"Using the dask gateway"},{"location":"using_the_dask_gateway/#using-the-dask-gateway","text":"","title":"Using the Dask gateway"},{"location":"using_the_dask_gateway/#what-is-dask","text":"Dask is a distributed computing framework for Python. It allows operations working on large datasets to be split across multiple computers (or multiple cores on the same computer). JASMIN offers a Dask gateway that allows jobs to run on up to 16 CPU cores on the Lotus cluster. This can be a convienient way to overcome the processor and memory limitations of the JASMIN notebook service, while still using that service to write and run your code.","title":"What is Dask?"},{"location":"using_the_dask_gateway/#requesting-access-to-the-dask-cluster","text":"Before using the Dask Cluster on JASMIN you must add it to your services. Please visit the additional services page on the JASMIN accounts portal This will need approval from the JASMIN staff and won't happen instantly.","title":"Requesting Access to the Dask Cluster"},{"location":"using_the_dask_gateway/#configuring-your-dask-environment","text":"There are some extra packages that aren't in the main CANARI environment that you'll need to run Dask. We've added these to another environment in the group workspace called dask-env. To make the Dask enviroment visible to Jupyter Lab, in a terminal on the notebook service run: mamba run -p /gws/smf/j04/canari/dask-env python -m ipykernel install --user --name CANARI-dask . After about one minute a new icon called \"CANARI-dask\" should appear in the Jupyter launcher. If you have existing Dask code then see the JASMIN documentation for an example of how to configure it to use the Dask gateway or see the examples below.","title":"Configuring your Dask environment"},{"location":"using_the_dask_gateway/#running-the-examples","text":"There are three dask examples in the tutorials git repository. If you cloned the repository before these were added (January 28th 2025) then you'll need to run a git pull operation to bring in the latest changes. In the files view in Jupyter Lab go to your copy of tutorials repository, click on the Git menu and choose \"Pull from Remote\". Or you can navigate to this directory in the terminal and type the command git pull . Three example files called dask-example1.ipynb , dask-example2.ipynb and dask-example-xarray.ipynb should appear. Open these, ensure they are using the CANARI-dask kernel and launch them. The first example demonstrates the Dask Delayed feature where calculations are not executed until their result is requested. The second example shows the futures feature where tasks are executed immediately, but anything wanting to access to the result will be forced to wait until the calculation is complete. The third example does use the dask gateway, but doesn't use dask directly. Instead it aims to replicate a more typical use of dask for this sprint - it uses xarray , which uses dask as long as it is installed, with some CANARI data to do some basic calculations and plotting. See this page for more information about how dask is integrated in xarray.","title":"Running the examples"},{"location":"using_the_dask_gateway/#accessing-the-dask-gateway-from-the-sci-servers","text":"You will need to generate a token for accessing the Dask gateway and place this in ~/.config/dask/gateway.yaml . See the JASMIN Dask documentation for details on how generate a token and the format of the config file.","title":"Accessing the Dask gateway from the sci servers"}]}